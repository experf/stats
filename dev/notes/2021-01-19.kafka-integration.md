Kafka Integration
==============================================================================

The plan is to have Stats push data to a `events` topic in Kafka, which passes
it down to Materialize, where Stats can query it with SQL (Postgres-flavor).

So we need to hook the Phoenix app up as a Kafka _producer_.

`event` Data
------------------------------------------------------------------------------

Should be as flexible as possible. Help make names and structures consistent at
the source, not in the data layer. If it makes it here, save it, sort it out
later.

I'm thinking JSON format. It's so damn universal, stable, and simple.

It looks like [Apache Avro][avro] is the popular fast, schema serialization 
people are using with Kafka, but I doubt we want anything like that at the 
`event` level.

[avro]: https://avro.apache.org/docs/current/

Client
------------------------------------------------------------------------------

So... looks like Elixir/Kafka is a bit of a mess:

1.  [KafkaEx][] ⭐️ 459 ❗ 32
    -   Has some weird rolling merge with [Kayrock][]..?
    
2.  [Kayrock][] ⭐️ 17 ❗ 0
    -   Based on [kafka_protocol][]
    
3.  [kafka_protocol][] ⭐️ 67 ❗ 4
    -   Erlang
    -   Used by [brod][]

4.  [brod][] ⭐️ 492 ❗ 19
    -   Erlang
    -   Depends on [kafka_protocol][]
    
4.  [Kaffe][] ⭐️ 106 ❗ 11
    -   Wrapper around [brod][]
    
5.  [KaufmannEx][] ⭐️ 86 ❗ 1
    -   Depends on [kafka_ex][], as well as `AvroEx` and `Schemex`
    -   https://medium.com/@7mind_dev/kaufmann-ex-317415c27978

[KafkaEx]: https://github.com/kafkaex/kafka_ex
[Kaffe]: https://github.com/spreedly/kaffe
[KaufmannEx]: https://github.com/sevenmind/kaufmann_ex
[Kayrock]: https://github.com/dantswain/kayrock
[kafka_protocol]: https://github.com/klarna/kafka_protocol
[brod]: https://github.com/klarna/brod
